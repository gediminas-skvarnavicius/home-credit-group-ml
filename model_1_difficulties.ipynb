{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Credits Where Difficulties Ocurred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gediminas/anaconda3/lib/python3.9/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/gediminas/anaconda3/lib/python3.9/site-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "import os\n",
    "import warnings\n",
    "import mlflow\n",
    "from pprint import pprint\n",
    "import random\n",
    "import polars as pl\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from rgf.sklearn import RGFClassifier\n",
    "import auxiliary.transformers as tr\n",
    "from auxiliary.transformers import PolarsColumnTransformer as PCT\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import copy\n",
    "import auxiliary.tuning as tunes\n",
    "import auxiliary.eda_functions as eda\n",
    "from ray import tune\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from BorutaShap import BorutaShap\n",
    "import statistics\n",
    "from sklearn.utils.validation import check_random_state\n",
    "%aimport auxiliary.transformers\n",
    "%aimport auxiliary.tuning\n",
    "%aimport auxiliary.eda_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Settings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=UserWarning, message=\"Cannot find FastRGF executable files.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pl.read_parquet('temp/application_train_filtered.parquet')\n",
    "id_and_target=['SK_ID_CURR','TARGET']\n",
    "X_train=train_data.drop(columns=id_and_target)\n",
    "y_train=train_data['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specifying categoric numeric and boolean features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_features = []\n",
    "for feature in X_train.select(pl.col(pl.Utf8)).columns:\n",
    "    if X_train[feature].n_unique() == 2:\n",
    "        bool_features.append(feature)\n",
    "\n",
    "cat_features = [\n",
    "    feature\n",
    "    for feature in X_train.select(pl.col(pl.Utf8)).columns\n",
    "    if feature not in bool_features\n",
    "]\n",
    "\n",
    "numeric_features_with_nulls = (\n",
    "    pl.Series(\n",
    "        X_train.select(pl.col(pl.FLOAT_DTYPES), pl.col(pl.INTEGER_DTYPES)).columns\n",
    "    )\n",
    "    .filter(\n",
    "        X_train.select(pl.col(pl.FLOAT_DTYPES), pl.col(pl.INTEGER_DTYPES))\n",
    "        .select(pl.all().is_null().any())\n",
    "        .transpose()\n",
    "        .to_series()\n",
    "    )\n",
    "    .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([])\n",
    "\n",
    "num_imputer = tr.PolarsColumnTransformer([])\n",
    "for feature in numeric_features_with_nulls:\n",
    "    num_imputer.steps[feature] = PCT.Step(\n",
    "        feature, tr.NumDiffFromRestImputer(), feature\n",
    "    )\n",
    "preprocessing.steps.insert(0,('num_imputer', num_imputer))\n",
    "\n",
    "cat_imputers = tr.PolarsColumnTransformer([])\n",
    "for feature in cat_features:\n",
    "    cat_imputers.steps[feature] = PCT.Step(\n",
    "        feature, tr.NotInImputerPolars(min_values=100, fill_value=\"other\"), feature\n",
    "    )\n",
    "preprocessing.steps.append((\"cat_imputers\", cat_imputers))\n",
    "\n",
    "encoders = tr.PolarsColumnTransformer([])\n",
    "for feature in bool_features:\n",
    "    encoders.steps[feature] = PCT.Step(\n",
    "        feature, tr.PolarsOneHotEncoder(drop=True), feature\n",
    "    )\n",
    "for feature in cat_features:\n",
    "    encoders.steps[feature] = PCT.Step(\n",
    "        feature, tr.TargetMeanOrderedLabeler(how=\"label\"), feature\n",
    "    )\n",
    "preprocessing.steps.append((\"encoders\", encoders))\n",
    "preprocessing.steps.append((\"emergency_null_imputer\", tr.PolarsNullImputer(-9999)))\n",
    "feature_remover = tr.FeatureRemover([])\n",
    "preprocessing.steps.append((\"feature_removal\", feature_remover))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models and Sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb=LGBMClassifier(n_jobs=1,verbosity=-1,force_col_wise=True)\n",
    "sampler_model=tr.SamplingModelWrapper(model_lgb)\n",
    "full_pipeline=Pipeline([('preprocess', preprocessing),('model',sampler_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_etrees=copy.deepcopy(preprocessing)\n",
    "model_extra_trees = ExtraTreesClassifier(random_state=1,n_jobs=1)\n",
    "sampler_model_etrees=tr.SamplingModelWrapper(model_extra_trees)\n",
    "full_pipeline_etrees=Pipeline([('preprocess',preprocessing_etrees),('model',sampler_model_etrees)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_rgf = copy.deepcopy(preprocessing)\n",
    "model_rgf = RGFClassifier()\n",
    "sampler_model_rgf=tr.SamplingModelWrapper(model_rgf)\n",
    "full_pipeline_rgf = Pipeline([(\"preprocess\", preprocessing_rgf), (\"model\", sampler_model_rgf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting Boruta Shap algorithm on LGBM models with different alpha regularization values**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_for_selection_high_reg=LGBMClassifier(verbose=-1,random_state=1,reg_alpha=10,num_leaves=100)\n",
    "selector_high_alpha=BorutaShap(importance_measure='shap',model=model_for_selection_high_reg)\n",
    "selector_high_alpha.fit(\n",
    "    full_pipeline[\"preprocess\"]\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .to_pandas(),\n",
    "    y_train.to_pandas(),\n",
    ")\n",
    "joblib.dump(selector_high_alpha,'temp/model_1_selector_alpha10.joblib')\n",
    "\n",
    "model_for_selection_reg=LGBMClassifier(verbose=-1,random_state=1,reg_alpha=1,num_leaves=100)\n",
    "selector_with_alpha=BorutaShap(importance_measure='shap',model=model_for_selection_reg)\n",
    "selector_with_alpha.fit(\n",
    "    full_pipeline[\"preprocess\"]\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .to_pandas(),\n",
    "    y_train.to_pandas(),\n",
    ")\n",
    "joblib.dump(selector_with_alpha,'temp/model_1_selector_alpha1.joblib')\n",
    "\n",
    "model_for_selection_noreg=LGBMClassifier(verbose=-1,random_state=1,reg_alpha=0,num_leaves=100)\n",
    "selector_no_alpha=BorutaShap(importance_measure='shap',model=model_for_selection_noreg)\n",
    "selector_no_alpha.fit(\n",
    "    full_pipeline[\"preprocess\"]\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .to_pandas(),\n",
    "    y_train.to_pandas(),\n",
    ")\n",
    "joblib.dump(selector_no_alpha,'temp/model_1_selector_alpha0.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating lists of bad and tentative feature lists for each selection experiment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_with_alpha=joblib.load('temp/model_1_selector_alpha1.joblib')\n",
    "selector_high_alpha=joblib.load('temp/model_1_selector_alpha10.joblib')\n",
    "selector_no_alpha=joblib.load('temp/model_1_selector_alpha0.joblib')\n",
    "bad_features_with_alpha=selector_with_alpha.features_to_remove.tolist()\n",
    "bad_and_tentative_features_alpha=bad_features_with_alpha.copy()\n",
    "bad_and_tentative_features_alpha.extend(selector_with_alpha.tentative.copy())\n",
    "\n",
    "\n",
    "bad_features_high_alpha=selector_high_alpha.features_to_remove.tolist()\n",
    "bad_and_tentative_features_high_alpha=bad_features_high_alpha.copy()\n",
    "bad_and_tentative_features_high_alpha.extend(selector_high_alpha.tentative.copy())\n",
    "\n",
    "\n",
    "bad_feature_no_alpha=selector_no_alpha.features_to_remove.tolist()\n",
    "bad_and_tentative_features_no_alpha=bad_feature_no_alpha.copy()\n",
    "bad_and_tentative_features_no_alpha.extend(selector_no_alpha.tentative.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Putting the feature quality data into a single data frame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_quality = {\"feature\": preprocessing.fit_transform(X_train, y_train).columns}\n",
    "feature_quality[\"high_alpha\"] = []\n",
    "feature_quality[\"alpha\"] = []\n",
    "feature_quality[\"no_alpha\"] = []\n",
    "\n",
    "for feature in feature_quality[\"feature\"]:\n",
    "    if feature in bad_features_high_alpha:\n",
    "        feature_quality[\"high_alpha\"].append(\"bad\")\n",
    "    elif feature in selector_high_alpha.tentative:\n",
    "        feature_quality[\"high_alpha\"].append(\"tentative\")\n",
    "    else:\n",
    "        feature_quality[\"high_alpha\"].append(\"good\")\n",
    "\n",
    "for feature in feature_quality[\"feature\"]:\n",
    "    if feature in bad_features_with_alpha:\n",
    "        feature_quality[\"alpha\"].append(\"bad\")\n",
    "    elif feature in selector_with_alpha.tentative:\n",
    "        feature_quality[\"alpha\"].append(\"tentative\")\n",
    "    else:\n",
    "        feature_quality[\"alpha\"].append(\"good\")\n",
    "\n",
    "for feature in feature_quality[\"feature\"]:\n",
    "    if feature in bad_features_high_alpha:\n",
    "        feature_quality[\"no_alpha\"].append(\"bad\")\n",
    "    elif feature in selector_no_alpha.tentative:\n",
    "        feature_quality[\"no_alpha\"].append(\"tentative\")\n",
    "    else:\n",
    "        feature_quality[\"no_alpha\"].append(\"good\")\n",
    "\n",
    "feature_quality=pl.DataFrame(feature_quality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features with no consensus:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| feature                                   | high_alpha   | alpha     | no_alpha   |\n",
       "|:------------------------------------------|:-------------|:----------|:-----------|\n",
       "| AMT_INCOME_TOTAL                          | good         | good      | tentative  |\n",
       "| DAYS_REGISTRATION                         | tentative    | good      | good       |\n",
       "| FLAG_WORK_PHONE                           | tentative    | good      | good       |\n",
       "| LIVINGAREA_MEDI                           | bad          | tentative | bad        |\n",
       "| DEF_60_CNT_SOCIAL_CIRCLE                  | bad          | tentative | bad        |\n",
       "| bureau_DAYS_CREDIT_ENDDATE_max            | tentative    | tentative | good       |\n",
       "| bureau_AMT_CREDIT_MAX_OVERDUE_max         | tentative    | tentative | good       |\n",
       "| bureau_AMT_CREDIT_SUM_mean                | tentative    | good      | good       |\n",
       "| bureau_AMT_CREDIT_SUM_max                 | tentative    | tentative | good       |\n",
       "| bureau_AMT_CREDIT_SUM_LIMIT_mean          | bad          | tentative | bad        |\n",
       "| bureau_DAYS_CREDIT_mean                   | tentative    | good      | good       |\n",
       "| bureau_DAYS_CREDIT_sum                    | bad          | tentative | bad        |\n",
       "| bureau_DAYS_CREDIT_UPDATE_std             | bad          | tentative | bad        |\n",
       "| bureau_DAYS_CREDIT_ENDDATE_mean_Active    | tentative    | good      | good       |\n",
       "| bureau_DAYS_CREDIT_ENDDATE_mode_Active    | bad          | tentative | bad        |\n",
       "| bureau_AMT_CREDIT_MAX_OVERDUE_mean_Active | bad          | tentative | bad        |\n",
       "| bureau_AMT_CREDIT_SUM_mean_Active         | bad          | tentative | bad        |\n",
       "| bureau_AMT_CREDIT_SUM_DEBT_sum_Active     | bad          | tentative | bad        |\n",
       "| bureau_DAYS_CREDIT_mean_Active            | bad          | tentative | bad        |\n",
       "| prev_AMT_CREDIT_mean_Approved             | bad          | tentative | bad        |\n",
       "| prev_AMT_CREDIT_sum_Revolving_loans       | tentative    | tentative | good       |\n",
       "| NAME_INCOME_TYPE                          | tentative    | good      | good       |\n",
       "| NAME_HOUSING_TYPE                         | bad          | tentative | bad        |\n",
       "| WALLSMATERIAL_MODE                        | bad          | tentative | bad        |\n",
       "| NAME_CONTRACT_TYPE_Cash loans             | tentative    | good      | good       |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.table_display(feature_quality.filter(\n",
    "    (pl.col(\"high_alpha\") != pl.col(\"alpha\"))\n",
    "    | (pl.col(\"high_alpha\") != pl.col(\"no_alpha\"))\n",
    "    | (pl.col(\"alpha\") != pl.col(\"no_alpha\"))\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating lists of bad and tentative features from consensus:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_quality = feature_quality.with_columns(\n",
    "    feature_quality.map_rows(lambda x: statistics.mode(x[1:]))\n",
    "    .to_series()\n",
    "    .alias(\"consensus\")\n",
    ")\n",
    "\n",
    "consensus_bad_tentative_features = feature_quality.filter(\n",
    "    pl.col(\"consensus\") != \"good\"\n",
    ")[\"feature\"].to_list()\n",
    "consensus_bad_features = feature_quality.filter(pl.col(\"consensus\") == \"bad\")[\n",
    "    \"feature\"\n",
    "].to_list()\n",
    "feature_removal_list = [consensus_bad_features, consensus_bad_tentative_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Search Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM parameter space:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tunes.Models()\n",
    "model_params_lgb = {\n",
    "    \"max_depth\": tune.randint(5, 30),\n",
    "    \"num_leaves\": tune.randint(10, 1000),\n",
    "    \"n_estimators\": tune.randint(10, 251),\n",
    "    \"learning_rate\": tune.loguniform(0.001, 0.1),\n",
    "    \"bagging_freq\": tune.randint(0, 11),\n",
    "    \"colsample_bytree\": tune.uniform(0.2, 1.0),\n",
    "    \"subsample\": tune.uniform(0.2, 1.0),\n",
    "    \"reg_alpha\": tune.loguniform(0.001, 100),\n",
    "    \"reg_lambda\": tune.loguniform(0.001, 100),\n",
    "    \"boosting_type\": tune.choice([\"gbdt\", \"dart\", \"rf\"]),\n",
    "    \"class_weight\": tune.choice([\"balanced\", None]),\n",
    "    \"max_bin\": tune.randint(5, 201),\n",
    "}\n",
    "\n",
    "search_space_lgbm = {\n",
    "    \"preprocess__feature_removal__feats_to_drop\": tune.choice(feature_removal_list),\n",
    "    \"model__model_params\": model_params_lgb,\n",
    "    \"model__sampler\": tune.choice(['random',None])\n",
    "}\n",
    "\n",
    "models.add_model(\n",
    "    \"lgbm\", full_pipeline, search_space_lgbm, metric_threshold=0.77\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Trees parameter space:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_extra_trees = {\n",
    "    \"n_estimators\": tune.randint(10, 251),\n",
    "    \"max_depth\": tune.randint(5, 30),\n",
    "    \"max_leaf_nodes\": tune.randint(30,1000),\n",
    "    \"min_samples_split\": tune.randint(2, 21),\n",
    "    \"min_samples_leaf\": tune.randint(1, 21),\n",
    "    \"max_features\": tune.uniform(0.1,1.0),\n",
    "    \"class_weight\": tune.choice([\"balanced\",\"balanced_subsample\" , None]),\n",
    "    \"max_samples\": tune.uniform(0.1, 1.0),\n",
    "}\n",
    "\n",
    "search_space_extra_trees = {\n",
    "    \"preprocess__feature_removal__feats_to_drop\": tune.choice(feature_removal_list),\n",
    "    \"model__model_params\": model_params_extra_trees,\n",
    "    \"model__sampler\": tune.choice(['random', None])\n",
    "}\n",
    "\n",
    "models.add_model(\n",
    "    \"extra_trees\", full_pipeline_etrees, search_space_extra_trees, metric_threshold=0.73\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized Greedy Forest parameter space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_rgf = {\n",
    "    \"algorithm\": tune.choice([\"RGF\", \"RGF Opt\", \"RGF Sib\"]),\n",
    "    \"loss\": tune.choice([\"LS\", \"Expo\", \"Log\", \"Abs\"]),\n",
    "    \"l2\": tune.loguniform(1e-6, 1.0),\n",
    "    \"max_leaf\": tune.randint(10, 1000),\n",
    "    \"test_interval\": tune.quniform(100,1000,100),\n",
    "    \"reg_depth\": tune.randint(1, 21),\n",
    "    \"learning_rate\": tune.loguniform(1e-6, 1.0),\n",
    "}\n",
    "\n",
    "search_space_rgf = {\n",
    "    \"preprocess__feature_removal__feats_to_drop\": tune.choice(feature_removal_list),\n",
    "    \"model__model_params\": model_params_rgf,\n",
    "    \"model__sampler\": tune.choice(['random', None])\n",
    "}\n",
    "\n",
    "models.add_model(\n",
    "    \"rgf\", full_pipeline_rgf, search_space_rgf, metric_threshold=0.76\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning of each model and saving the results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-11-12 20:21:10</td></tr>\n",
       "<tr><td>Running for: </td><td>00:03:01.72        </td></tr>\n",
       "<tr><td>Memory:      </td><td>19.6/31.2 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 12.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc                </th><th>model__model_params/\n",
       "algorithm        </th><th style=\"text-align: right;\">            model__model_params/\n",
       "l2</th><th style=\"text-align: right;\">            model__model_params/\n",
       "learning_rate</th><th>model__model_params/\n",
       "loss     </th><th style=\"text-align: right;\">    model__model_params/\n",
       "max_leaf</th><th style=\"text-align: right;\">   model__model_params/\n",
       "reg_depth</th><th style=\"text-align: right;\">    model__model_params/\n",
       "test_interval</th><th>model__sampler  </th><th>...ocess__feature_re\n",
       "moval__feats_to_drop                     </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TrainableCV_8d6d752f</td><td>RUNNING   </td><td>192.168.0.103:17297</td><td>RGF    </td><td style=\"text-align: right;\">0.0203939  </td><td style=\"text-align: right;\">2.90761e-06</td><td>Expo</td><td style=\"text-align: right;\">915</td><td style=\"text-align: right;\">20</td><td style=\"text-align: right;\">400</td><td>random          </td><td>[&#x27;CNT_CHILDREN&#x27;_b4c0</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        139.603 </td><td style=\"text-align: right;\">0.761098</td></tr>\n",
       "<tr><td>TrainableCV_61671ae0</td><td>RUNNING   </td><td>192.168.0.103:17513</td><td>RGF Sib</td><td style=\"text-align: right;\">0.530082   </td><td style=\"text-align: right;\">9.99658e-06</td><td>Expo</td><td style=\"text-align: right;\">188</td><td style=\"text-align: right;\"> 4</td><td style=\"text-align: right;\">800</td><td>random          </td><td>[&#x27;CNT_CHILDREN&#x27;_5280</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        108.638 </td><td style=\"text-align: right;\">0.765937</td></tr>\n",
       "<tr><td>TrainableCV_6ab24afa</td><td>RUNNING   </td><td>192.168.0.103:17568</td><td>RGF Sib</td><td style=\"text-align: right;\">0.000788554</td><td style=\"text-align: right;\">0.113716   </td><td>Abs </td><td style=\"text-align: right;\">641</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">500</td><td>random          </td><td>[&#x27;CNT_CHILDREN&#x27;_6c80</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        140.792 </td><td style=\"text-align: right;\">0.761098</td></tr>\n",
       "<tr><td>TrainableCV_c6ac413f</td><td>RUNNING   </td><td>192.168.0.103:17763</td><td>RGF    </td><td style=\"text-align: right;\">0.00506978 </td><td style=\"text-align: right;\">0.00180062 </td><td>Abs </td><td style=\"text-align: right;\">102</td><td style=\"text-align: right;\">20</td><td style=\"text-align: right;\">400</td><td>                </td><td>[&#x27;CNT_CHILDREN&#x27;_ea00</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         81.5719</td><td style=\"text-align: right;\">0.763159</td></tr>\n",
       "<tr><td>TrainableCV_8f7b6d44</td><td>RUNNING   </td><td>192.168.0.103:17889</td><td>RGF Opt</td><td style=\"text-align: right;\">0.0348608  </td><td style=\"text-align: right;\">0.000113257</td><td>Expo</td><td style=\"text-align: right;\"> 87</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">300</td><td>                </td><td>[&#x27;CNT_CHILDREN&#x27;_2c00</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>TrainableCV_0df292f3</td><td>RUNNING   </td><td>192.168.0.103:17966</td><td>RGF Opt</td><td style=\"text-align: right;\">0.00233672 </td><td style=\"text-align: right;\">0.00722399 </td><td>LS  </td><td style=\"text-align: right;\">618</td><td style=\"text-align: right;\">13</td><td style=\"text-align: right;\">500</td><td>                </td><td>[&#x27;CNT_CHILDREN&#x27;_8180</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>TrainableCV_0a41528e</td><td>PENDING   </td><td>                   </td><td>RGF    </td><td style=\"text-align: right;\">5.68898e-06</td><td style=\"text-align: right;\">1.02558e-06</td><td>Expo</td><td style=\"text-align: right;\">922</td><td style=\"text-align: right;\"> 6</td><td style=\"text-align: right;\">700</td><td>smote           </td><td>[&#x27;CNT_CHILDREN&#x27;_6480</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>TrainableCV_9fd40e7b</td><td>TERMINATED</td><td>192.168.0.103:17230</td><td>RGF Sib</td><td style=\"text-align: right;\">0.00169005 </td><td style=\"text-align: right;\">0.00404288 </td><td>Abs </td><td style=\"text-align: right;\">804</td><td style=\"text-align: right;\"> 9</td><td style=\"text-align: right;\">700</td><td>smote           </td><td>[&#x27;CNT_CHILDREN&#x27;_2980</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         70.7546</td><td style=\"text-align: right;\">0.72962 </td></tr>\n",
       "<tr><td>TrainableCV_ceceff1b</td><td>TERMINATED</td><td>192.168.0.103:17400</td><td>RGF    </td><td style=\"text-align: right;\">0.747971   </td><td style=\"text-align: right;\">0.000174319</td><td>Log </td><td style=\"text-align: right;\">906</td><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">700</td><td>smote           </td><td>[&#x27;CNT_CHILDREN&#x27;_3c40</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         72.0023</td><td style=\"text-align: right;\">0.72962 </td></tr>\n",
       "<tr><td>TrainableCV_264cdba0</td><td>TERMINATED</td><td>192.168.0.103:17455</td><td>RGF    </td><td style=\"text-align: right;\">0.00575689 </td><td style=\"text-align: right;\">5.82704e-06</td><td>Abs </td><td style=\"text-align: right;\">785</td><td style=\"text-align: right;\">11</td><td style=\"text-align: right;\">300</td><td>                </td><td>[&#x27;CNT_CHILDREN&#x27;_d340</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        133.434 </td><td style=\"text-align: right;\">0.766019</td></tr>\n",
       "<tr><td>TrainableCV_f4dc52e4</td><td>TERMINATED</td><td>192.168.0.103:17670</td><td>RGF    </td><td style=\"text-align: right;\">0.272845   </td><td style=\"text-align: right;\">7.09032e-05</td><td>LS  </td><td style=\"text-align: right;\"> 13</td><td style=\"text-align: right;\">12</td><td style=\"text-align: right;\">900</td><td>smote           </td><td>[&#x27;CNT_CHILDREN&#x27;_3a00</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         76.3685</td><td style=\"text-align: right;\">0.72962 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TrainableCV pid=17455)\u001b[0m Step 0 F-1 Score: 0.7804386621540746\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17297)\u001b[0m Step 0 F-1 Score: 0.7765758769922815\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17455)\u001b[0m Step 1 F-1 Score: 0.7541195901851638\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17568)\u001b[0m Step 0 F-1 Score: 0.7765758769922815\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17400)\u001b[0m Step 0 F-1 Score: 0.7296203522711942\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17455)\u001b[0m Step 2 F-1 Score: 0.7549184163732933\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17297)\u001b[0m Step 1 F-1 Score: 0.7538148437143677\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17763)\u001b[0m Step 0 F-1 Score: 0.7804386621540746\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17568)\u001b[0m Step 1 F-1 Score: 0.7538148437143677\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17513)\u001b[0m Step 1 F-1 Score: 0.7548182471503466\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17763)\u001b[0m Step 1 F-1 Score: 0.7541195901851638\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17297)\u001b[0m Step 2 F-1 Score: 0.7529046341417167\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17670)\u001b[0m Step 0 F-1 Score: 0.7296203522711942\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17568)\u001b[0m Step 2 F-1 Score: 0.7529046341417167\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=17763)\u001b[0m Step 2 F-1 Score: 0.7549184163732933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 20:21:09,879\tWARNING tune.py:194 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    }
   ],
   "source": [
    "# models.models['lgbm'].tune_model(X_train,y_train, n=200,metric='roc_auc')\n",
    "# joblib.dump(models,\"temp/model_1_tuned_models.joblib\")\n",
    "# models=joblib.load('temp/model_1_tuned_models.joblib')\n",
    "# models.models['extra_trees'].tune_model(X_train,y_train, n=100,metric='roc_auc')\n",
    "# joblib.dump(models,\"temp/model_1_tuned_models.joblib\")\n",
    "models.models['rgf'].tune_model(X_train,y_train, n=50,metric='roc_auc',sample_size=50000)\n",
    "# joblib.dump(models,\"temp/model_1_tuned_models.joblib\")\n",
    "# models.tune_all(X_train,y_train,metric='roc_auc',sample_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the tuned models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=joblib.load(\"temp/model_1_tuned_models.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm\n",
      "----------------\n",
      "'model__model_params:'\n",
      "{'bagging_freq': 4,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'class_weight': None,\n",
      " 'colsample_bytree': 0.8014252957700048,\n",
      " 'learning_rate': 0.024615541208760996,\n",
      " 'max_bin': 195,\n",
      " 'max_depth': 11,\n",
      " 'n_estimators': 130,\n",
      " 'num_leaves': 850,\n",
      " 'reg_alpha': 0.1867708640086517,\n",
      " 'reg_lambda': 0.05040568844637988,\n",
      " 'subsample': 0.3674293085589498}\n",
      "\n",
      "'model__sampler:'\n",
      "'random'\n",
      "\n",
      "extra_trees\n",
      "----------------\n",
      "'model__model_params:'\n",
      "{'class_weight': 'balanced_subsample',\n",
      " 'max_depth': 17,\n",
      " 'max_features': 0.6415290560036582,\n",
      " 'max_leaf_nodes': 184,\n",
      " 'max_samples': 0.4259865167145781,\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 18,\n",
      " 'n_estimators': 222}\n",
      "\n",
      "'model__sampler:'\n",
      "None\n",
      "\n",
      "rgf\n",
      "----------------\n",
      "'model__model_params:'\n",
      "{'algorithm': 'RGF Opt',\n",
      " 'l2': 0.0017590322410677072,\n",
      " 'learning_rate': 0.00023978850531378984,\n",
      " 'loss': 'Log',\n",
      " 'max_leaf': 908,\n",
      " 'reg_depth': 1,\n",
      " 'test_interval': 700.0}\n",
      "\n",
      "'model__sampler:'\n",
      "'random'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models.models.values():\n",
    "    print(model.name)\n",
    "    print(\"----------------\")\n",
    "    for key,param in model.best_params.items():\n",
    "        if key[:3]==\"mod\":\n",
    "            pprint(key+\":\")\n",
    "            pprint(param)\n",
    "            print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which features have been removed for each model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm\n",
      "Only bad features removed\n",
      "\n",
      "extra_trees\n",
      "Bad and Tentative features removed\n",
      "\n",
      "rgf\n",
      "Bad and Tentative features removed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models.models.values():\n",
    "    print(model.name)\n",
    "    if model.best_params['preprocess__feature_removal__feats_to_drop']==consensus_bad_features:\n",
    "        print(\"Only bad features removed\")\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(\"Bad and Tentative features removed\")\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KFold Cross-validations of each model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb Cell 49\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#X66sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mlflow\u001b[39m.\u001b[39mset_experiment(\u001b[39m\"\u001b[39m\u001b[39mCredit Risk\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#X66sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#X66sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     scores[model\u001b[39m.\u001b[39mname]\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray(model\u001b[39m.\u001b[39;49mcross_val_roc_auc(X_train,y_train))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#X66sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39mstart_run(run_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m_cross_val\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m run:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#X66sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         mlflow\u001b[39m.\u001b[39mlog_params(model\u001b[39m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m~/Documents/turing_projects/module3_s4/gskvar-ML.4/auxiliary/tuning.py:328\u001b[0m, in \u001b[0;36mModels.Model.cross_val_roc_auc\u001b[0;34m(self, X, y, n, n_jobs)\u001b[0m\n\u001b[1;32m    325\u001b[0m cv \u001b[39m=\u001b[39m StratifiedKFold(n)\n\u001b[1;32m    326\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs)\n\u001b[0;32m--> 328\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    329\u001b[0m     delayed(process_fold)(train_index, test_index, X, y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline)\n\u001b[1;32m    330\u001b[0m     \u001b[39mfor\u001b[39;49;00m train_index, test_index \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y)\n\u001b[1;32m    331\u001b[0m )\n\u001b[1;32m    333\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores={}\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Credit Risk\")\n",
    "for model in models.models.values():\n",
    "    scores[model.name]=np.array(model.cross_val_roc_auc(X_train,y_train))\n",
    "    with mlflow.start_run(run_name=f\"{model.name}_cross_val\") as run:\n",
    "\n",
    "        mlflow.log_params(model.best_params)\n",
    "\n",
    "        mlflow.log_metric(\"mean_roc_auc\",scores[model.name].mean())\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model.pipeline, artifact_path=f\"temp/mlflow/{model.name}_cross_val\"\n",
    "    )\n",
    "    mlflow.end_run()\n",
    "scores=pl.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb Cell 50\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fig_scores,ax_scores\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39msubplots()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#Y100sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sns\u001b[39m.\u001b[39mboxplot(scores)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#Y100sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ax_scores\u001b[39m.\u001b[39mset_xticklabels(scores\u001b[39m.\u001b[39;49mcolumns)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#Y100sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'columns'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_scores,ax_scores=plt.subplots()\n",
    "sns.boxplot(scores)\n",
    "ax_scores.set_xticklabels(scores.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator = LGBMClassifier(random_state=1, n_jobs=1,verbose=-1)\n",
    "model_stack = tr.SimplerStacker(\n",
    "    [model.pipeline for model in models.models.values()],\n",
    "    final_estimator=final_estimator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/auxiliary/transformers.py\", line 892, in train_and_predict\n    return model.predict_proba(X_test)[:, 1]\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 585, in predict_proba\n    return self.steps[-1][1].predict_proba(Xt, **predict_proba_params)\n  File \"/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/auxiliary/transformers.py\", line 833, in predict_proba\n    predictions = self.model.predict_proba(X)\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 865, in predict_proba\n    X = self._validate_X_predict(X)\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 599, in _validate_X_predict\n    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 605, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 957, in check_array\n    _assert_all_finite(\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 122, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/home/gediminas/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 171, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb Cell 58\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#Y104sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m stacked_model_scores\u001b[39m=\u001b[39m[]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#Y104sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m train_index, test_index \u001b[39min\u001b[39;00m splitter\u001b[39m.\u001b[39msplit(X_train,y_train):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#Y104sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model_stack\u001b[39m.\u001b[39;49mfit(X_train[train_index],y_train[train_index])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#Y104sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     preds\u001b[39m=\u001b[39mmodel_stack\u001b[39m.\u001b[39mpredict_proba(X_train[test_index])[:,\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#Y104sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     stacked_model_scores\u001b[39m.\u001b[39mappend(roc_auc_score(y_train[test_index],preds))\n",
      "File \u001b[0;32m~/Documents/turing_projects/module3_s4/gskvar-ML.4/auxiliary/transformers.py:898\u001b[0m, in \u001b[0;36mSimplerStacker.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    895\u001b[0m y_pred_cv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(y, dtype\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m)\n\u001b[1;32m    897\u001b[0m \u001b[39m# Perform parallelized cross-validated predictions\u001b[39;00m\n\u001b[0;32m--> 898\u001b[0m results \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)(\n\u001b[1;32m    899\u001b[0m     delayed(train_and_predict)(train_index, test_index)\n\u001b[1;32m    900\u001b[0m     \u001b[39mfor\u001b[39;49;00m train_index, test_index \u001b[39min\u001b[39;49;00m kf\u001b[39m.\u001b[39;49msplit(X, y)\n\u001b[1;32m    901\u001b[0m )\n\u001b[1;32m    902\u001b[0m \u001b[39mfor\u001b[39;00m i, (train_index, test_index) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(kf\u001b[39m.\u001b[39msplit(X, y)):\n\u001b[1;32m    903\u001b[0m     y_pred_cv[test_index] \u001b[39m=\u001b[39m results[i]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "stacked_model_scores=[]\n",
    "for train_index, test_index in splitter.split(X_train,y_train):\n",
    "    model_stack.fit(X_train[train_index],y_train[train_index])\n",
    "    preds=model_stack.predict_proba(X_train[test_index])[:,1]\n",
    "    stacked_model_scores.append(roc_auc_score(y_train[test_index],preds))\n",
    "joblib.dump(stacked_model_scores,\"temp/stack_scores.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7300480775310794]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 33, 157, 103,  92,  31, 139,  91,  45,  74,  60,  11,  29, 170,\n",
       "       158, 147,  22,  48,  14,  19,  35,  37,  38,  41,  17,  20,  10,\n",
       "        36,  29,  47,  45,  33,  28,  31,  20,  16,  28,  31,  41,  40,\n",
       "        20,  26,  51,  24,  36,  66,  31,  23,  28,  93,  13,  29,  25,\n",
       "       113,  41,  56,  40,  13,  36,  28,  35,  15,  68,  24], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.models['lgbm'].pipeline['model'].model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=models.models['lgbm'].pipeline['preprocess'].fit_transform(X_train,y_train).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prev_payment_left'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats=pl.DataFrame({'imp':models.models['lgbm'].pipeline['model'].model.feature_importances_,'feat':cols})\n",
    "feats.sort('imp')[-6,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|   imp | feat                                     |\n",
       "|------:|:-----------------------------------------|\n",
       "|    10 | bureau_AMT_CREDIT_MAX_OVERDUE_max        |\n",
       "|    11 | FLAG_WORK_PHONE                          |\n",
       "|    13 | prev_AMT_CREDIT_sum_Revolving_loans      |\n",
       "|    13 | NAME_INCOME_TYPE                         |\n",
       "|    14 | FLAG_DOCUMENT_3                          |\n",
       "|    15 | WEEKDAY_APPR_PROCESS_START               |\n",
       "|    16 | bureau_DAYS_CREDIT_ENDDATE_sum_Active    |\n",
       "|    17 | bureau_AMT_CREDIT_MAX_OVERDUE_mean       |\n",
       "|    19 | AMT_REQ_CREDIT_BUREAU_QRT                |\n",
       "|    20 | bureau_AMT_CREDIT_MAX_OVERDUE_sum        |\n",
       "|    20 | bureau_DAYS_CREDIT_ENDDATE_mean_Active   |\n",
       "|    20 | bureau_AMT_CREDIT_SUM_DEBT_mean_Active   |\n",
       "|    22 | DEF_30_CNT_SOCIAL_CIRCLE                 |\n",
       "|    23 | prev_AMT_CREDIT_sum_Refused              |\n",
       "|    24 | bureau_DAYS_CREDIT_mode_Active           |\n",
       "|    24 | NAME_CONTRACT_TYPE_Cash loans            |\n",
       "|    25 | prev_count_Refused                       |\n",
       "|    26 | bureau_AMT_CREDIT_SUM_DEBT_min_Active    |\n",
       "|    28 | bureau_DAYS_CREDIT_max                   |\n",
       "|    28 | bureau_DAYS_CREDIT_ENDDATE_min_Active    |\n",
       "|    28 | prev_AMT_CREDIT_mean_Consumer_loans      |\n",
       "|    28 | NAME_FAMILY_STATUS                       |\n",
       "|    29 | REGION_RATING_CLIENT_W_CITY              |\n",
       "|    29 | bureau_AMT_CREDIT_SUM_sum                |\n",
       "|    29 | prev_count_Approved                      |\n",
       "|    31 | REGION_POPULATION_RELATIVE               |\n",
       "|    31 | bureau_DAYS_CREDIT_mode                  |\n",
       "|    31 | bureau_DAYS_CREDIT_ENDDATE_max_Active    |\n",
       "|    31 | prev_AMT_CREDIT_mean_Refused             |\n",
       "|    33 | AMT_INCOME_TOTAL                         |\n",
       "|    33 | bureau_DAYS_CREDIT_mean                  |\n",
       "|    35 | bureau_DAYS_CREDIT_ENDDATE_max           |\n",
       "|    35 | OCCUPATION_TYPE                          |\n",
       "|    36 | bureau_AMT_CREDIT_SUM_mean               |\n",
       "|    36 | bureau_count_Active                      |\n",
       "|    36 | NAME_EDUCATION_TYPE                      |\n",
       "|    37 | bureau_DAYS_CREDIT_ENDDATE_mode          |\n",
       "|    38 | bureau_DAYS_ENDDATE_FACT_max             |\n",
       "|    40 | bureau_AMT_CREDIT_SUM_min_Active         |\n",
       "|    40 | CODE_GENDER                              |\n",
       "|    41 | bureau_DAYS_ENDDATE_FACT_std             |\n",
       "|    41 | bureau_AMT_CREDIT_MAX_OVERDUE_sum_Active |\n",
       "|    41 | prev_AMT_BALANCE_CURR_sum                |\n",
       "|    45 | DAYS_REGISTRATION                        |\n",
       "|    45 | bureau_AMT_CREDIT_SUM_DEBT_mean          |\n",
       "|    47 | bureau_AMT_CREDIT_SUM_max                |\n",
       "|    48 | DAYS_LAST_PHONE_CHANGE                   |\n",
       "|    51 | bureau_DAYS_CREDIT_max_Active            |\n",
       "|    56 | prev_curr_bal_lim_diff_sum               |\n",
       "|    60 | OWN_CAR_AGE                              |\n",
       "|    66 | prev_AMT_CREDIT_sum_Approved             |\n",
       "|    68 | ORGANIZATION_TYPE                        |\n",
       "|    74 | DAYS_ID_PUBLISH                          |\n",
       "|    91 | DAYS_EMPLOYED                            |\n",
       "|    92 | AMT_GOODS_PRICE                          |\n",
       "|    93 | prev_AMT_CREDIT_sum_Consumer_loans       |\n",
       "|   103 | AMT_ANNUITY                              |\n",
       "|   113 | prev_payment_left                        |\n",
       "|   139 | DAYS_BIRTH                               |\n",
       "|   147 | EXT_SOURCE_3                             |\n",
       "|   157 | AMT_CREDIT                               |\n",
       "|   158 | EXT_SOURCE_2                             |\n",
       "|   170 | EXT_SOURCE_1                             |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.table_display(feats.sort(\"imp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for train_index, test_index in StratifiedKFold(5).split(X_train, y_train):\n",
    "    models.models[\"lgbm\"].pipeline.fit(\n",
    "        X_train[train_index], y_train[train_index]\n",
    "    )\n",
    "    scores.append(\n",
    "        roc_auc_score(\n",
    "            y_train[test_index],\n",
    "            models.models[\"lgbm\"].pipeline.predict_proba(\n",
    "                X_train[test_index]\n",
    "            )[:,1],\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
