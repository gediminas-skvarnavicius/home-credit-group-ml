{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "import polars as pl\n",
    "from sklearn.pipeline import Pipeline\n",
    "import auxiliary.transformers as tr\n",
    "from auxiliary.transformers import PolarsColumnTransformer as PCT\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import copy\n",
    "import auxiliary.tuning as tunes\n",
    "from ray import tune\n",
    "import joblib\n",
    "import numpy as np\n",
    "from BorutaShap import BorutaShap\n",
    "%aimport auxiliary.transformers\n",
    "%aimport auxiliary.tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pl.read_parquet('temp/application_train_filtered.parquet')\n",
    "id_and_target=['SK_ID_CURR','TARGET']\n",
    "X_train=train_data.drop(columns=id_and_target)\n",
    "y_train=train_data['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_features = []\n",
    "for feature in X_train.select(pl.col(pl.Utf8)).columns:\n",
    "    if train_data[feature].n_unique() == 2:\n",
    "        bool_features.append(feature)\n",
    "\n",
    "cat_features = [\n",
    "    feature\n",
    "    for feature in X_train.select(pl.col(pl.Utf8)).columns\n",
    "    if feature not in bool_features\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing=Pipeline([])\n",
    "encoders=tr.PolarsColumnTransformer([])\n",
    "for feature in bool_features:\n",
    "    encoders.steps[feature]=PCT.Step(feature,tr.PolarsOneHotEncoder(drop=True),feature)\n",
    "for feature in cat_features:\n",
    "    encoders.steps[feature]=PCT.Step(feature,tr.TargetMeanOrderedLabeler(how='label'),feature)\n",
    "preprocessing.steps.append(('encoders',encoders))\n",
    "feature_remover=tr.FeatureRemover([])\n",
    "preprocessing.steps.append(('feature_removal',feature_remover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb=LGBMClassifier(n_jobs=1,verbosity=-1,force_col_wise=True)\n",
    "full_pipeline=Pipeline([('preprocess', preprocessing),('model',model_lgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_selection=LGBMClassifier(verbose=-1,random_state=1,reg_alpha=1)\n",
    "selector=BorutaShap(importance_measure='shap',model=model_for_selection)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "selector.fit(\n",
    "    full_pipeline[\"preprocess\"]\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .to_pandas(),\n",
    "    y_train.to_pandas(),\n",
    ")\n",
    "joblib.dump(selector,'temp/model_1_selector.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector=joblib.load('temp/model_1_selector.joblib')\n",
    "bad_features=selector.features_to_remove.tolist()\n",
    "bad_and_tentative_features=bad_features.copy()\n",
    "bad_and_tentative_features.extend(selector.tentative.copy())\n",
    "feature_removal_list=[bad_features,bad_and_tentative_features,[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tunes.Models()\n",
    "search_space_lgbm = {\n",
    "    \"preprocess__feature_removal__feats_to_drop\": tune.choice(feature_removal_list),\n",
    "    \"model__max_depth\": tune.randint(5, 50),\n",
    "    \"model__num_leaves\": tune.randint(10, 3051),\n",
    "    \"model__n_estimators\": tune.randint(10, 251),\n",
    "    \"model__learning_rate\": tune.loguniform(0.001, 0.1),\n",
    "    \"model__bagging_freq\": tune.randint(0, 11),\n",
    "    \"model__colsample_bytree\": tune.uniform(0.2, 1.0),\n",
    "    \"model__subsample\": tune.uniform(0.2, 1.0),\n",
    "    \"model__reg_alpha\": tune.loguniform(0.001, 100),\n",
    "    \"model__reg_lambda\": tune.loguniform(0.001, 100),\n",
    "    \"model__boosting_type\": tune.choice([\"gbdt\", \"dart\", \"rf\"]),\n",
    "    \"model__class_weight\": tune.choice([\"balanced\", None]),\n",
    "    \"model__max_bin\": tune.randint(5, 201),\n",
    "}\n",
    "\n",
    "models.add_model(\n",
    "    \"lgbm\", full_pipeline, search_space_lgbm, metric_threshold=0.75\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-10-31 14:39:29</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:37.65        </td></tr>\n",
       "<tr><td>Memory:      </td><td>17.1/31.2 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 8.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  model__bagging_freq</th><th>model__boosting_type  </th><th>model__class_weight  </th><th style=\"text-align: right;\">         model__colsample_byt\n",
       "ree</th><th style=\"text-align: right;\">  model__learning_rate</th><th style=\"text-align: right;\">  model__max_bin</th><th style=\"text-align: right;\">  model__max_depth</th><th style=\"text-align: right;\">  model__n_estimators</th><th style=\"text-align: right;\">  model__num_leaves</th><th style=\"text-align: right;\">  model__reg_alpha</th><th style=\"text-align: right;\">  model__reg_lambda</th><th style=\"text-align: right;\">  model__subsample</th><th>...ocess__feature_re\n",
       "moval__feats_to_drop                     </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TrainableCV_2b13eaf0</td><td>RUNNING   </td><td>192.168.0.103:60347</td><td style=\"text-align: right;\">                    9</td><td>dart                  </td><td>                     </td><td style=\"text-align: right;\">0.951897</td><td style=\"text-align: right;\">            0.00842985</td><td style=\"text-align: right;\">             200</td><td style=\"text-align: right;\">                22</td><td style=\"text-align: right;\">                  135</td><td style=\"text-align: right;\">               1344</td><td style=\"text-align: right;\">         0.0197627</td><td style=\"text-align: right;\">         0.00392994</td><td style=\"text-align: right;\">          0.249749</td><td>[&#x27;CNT_CHILDREN&#x27;_7440</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>TrainableCV_7e06b277</td><td>RUNNING   </td><td>192.168.0.103:60561</td><td style=\"text-align: right;\">                    3</td><td>rf                    </td><td>balanced             </td><td style=\"text-align: right;\">0.673844</td><td style=\"text-align: right;\">            0.053261  </td><td style=\"text-align: right;\">             110</td><td style=\"text-align: right;\">                12</td><td style=\"text-align: right;\">                   98</td><td style=\"text-align: right;\">                198</td><td style=\"text-align: right;\">         0.0553883</td><td style=\"text-align: right;\">         3.43321   </td><td style=\"text-align: right;\">          0.57669 </td><td>[&#x27;CNT_CHILDREN&#x27;_f580</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.87453</td><td style=\"text-align: right;\">0.751851</td></tr>\n",
       "<tr><td>TrainableCV_d089b988</td><td>RUNNING   </td><td>192.168.0.103:60616</td><td style=\"text-align: right;\">                    9</td><td>rf                    </td><td>balanced             </td><td style=\"text-align: right;\">0.882426</td><td style=\"text-align: right;\">            0.00137669</td><td style=\"text-align: right;\">             148</td><td style=\"text-align: right;\">                35</td><td style=\"text-align: right;\">                   69</td><td style=\"text-align: right;\">                 93</td><td style=\"text-align: right;\">         0.926264 </td><td style=\"text-align: right;\">        12.1264    </td><td style=\"text-align: right;\">          0.823256</td><td>[]                  </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>TrainableCV_08aba948</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">                    2</td><td>gbdt                  </td><td>                     </td><td style=\"text-align: right;\">0.200765</td><td style=\"text-align: right;\">            0.00325256</td><td style=\"text-align: right;\">             166</td><td style=\"text-align: right;\">                40</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">               1396</td><td style=\"text-align: right;\">         6.66413  </td><td style=\"text-align: right;\">         4.30869   </td><td style=\"text-align: right;\">          0.382349</td><td>[&#x27;CNT_CHILDREN&#x27;_6a40</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>TrainableCV_9238d9fc</td><td>TERMINATED</td><td>192.168.0.103:60392</td><td style=\"text-align: right;\">                    6</td><td>gbdt                  </td><td>balanced             </td><td style=\"text-align: right;\">0.708002</td><td style=\"text-align: right;\">            0.0042012 </td><td style=\"text-align: right;\">              51</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                  168</td><td style=\"text-align: right;\">                588</td><td style=\"text-align: right;\">         0.0373266</td><td style=\"text-align: right;\">         0.0127622 </td><td style=\"text-align: right;\">          0.884473</td><td>[&#x27;CNT_CHILDREN&#x27;_ffc0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.38939</td><td style=\"text-align: right;\">0.736847</td></tr>\n",
       "<tr><td>TrainableCV_c4ab68ca</td><td>TERMINATED</td><td>192.168.0.103:60442</td><td style=\"text-align: right;\">                    6</td><td>rf                    </td><td>                     </td><td style=\"text-align: right;\">0.526529</td><td style=\"text-align: right;\">            0.0143452 </td><td style=\"text-align: right;\">              63</td><td style=\"text-align: right;\">                33</td><td style=\"text-align: right;\">                   23</td><td style=\"text-align: right;\">               1550</td><td style=\"text-align: right;\">         0.507787 </td><td style=\"text-align: right;\">        38.2468    </td><td style=\"text-align: right;\">          0.759426</td><td>[]                  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.92924</td><td style=\"text-align: right;\">0.746506</td></tr>\n",
       "<tr><td>TrainableCV_841ea4d3</td><td>TERMINATED</td><td>192.168.0.103:60510</td><td style=\"text-align: right;\">                    5</td><td>rf                    </td><td>balanced             </td><td style=\"text-align: right;\">0.307918</td><td style=\"text-align: right;\">            0.0591202 </td><td style=\"text-align: right;\">              40</td><td style=\"text-align: right;\">                49</td><td style=\"text-align: right;\">                  119</td><td style=\"text-align: right;\">               1706</td><td style=\"text-align: right;\">         0.0919788</td><td style=\"text-align: right;\">         0.0090812 </td><td style=\"text-align: right;\">          0.209859</td><td>[&#x27;CNT_CHILDREN&#x27;_ae40</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.8527 </td><td style=\"text-align: right;\">0.749596</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TrainableCV pid=60392)\u001b[0m Step 0 F-1 Score: 0.7368467863248905\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=60442)\u001b[0m Step 0 F-1 Score: 0.7465060617288583\n",
      "\u001b[2m\u001b[36m(TrainableCV pid=60510)\u001b[0m Step 0 F-1 Score: 0.7495961418279152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 14:39:29,440\tWARNING tune.py:194 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TrainableCV pid=60561)\u001b[0m Step 1 F-1 Score: 0.7529663496394745\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 14:39:39,687\tINFO tune.py:1143 -- Total run time: 47.80 seconds (37.55 seconds for the tuning loop).\n",
      "2023-10-31 14:39:39,688\tWARNING tune.py:1158 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/tmp/tune_results/lgbm\", trainable=...)\n",
      "2023-10-31 14:39:39,694\tWARNING experiment_analysis.py:205 -- Failed to fetch metrics for 1 trial(s):\n",
      "- TrainableCV_08aba948: FileNotFoundError('Could not fetch metrics for TrainableCV_08aba948: both result.json and progress.csv were not found at /tmp/tune_results/lgbm/TrainableCV_08aba948_7_model__bagging_freq=2,model__boosting_type=gbdt,model__class_weight=None,model__colsample_bytree=0.2008,mod_2023-10-31_14-39-24')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm tuned.\n"
     ]
    }
   ],
   "source": [
    "models.tune_all(X_train,y_train,metric='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.models['lgbm_grade_single'].best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m extra_trees \u001b[39m=\u001b[39m ExtraTreesClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)     \u001b[39m# Random seed for reproducibility\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Train the Extra Trees classifier on the training data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#X51sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m extra_trees\u001b[39m.\u001b[39;49mfit(preprocessing\u001b[39m.\u001b[39;49mfit_transform(X_train,y_train), y_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    349\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[1;32m    350\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1147\u001b[0m     X,\n\u001b[1;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1149\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1150\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1151\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1152\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1153\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1154\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1155\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1156\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1157\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1158\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1160\u001b[0m )\n\u001b[1;32m   1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    954\u001b[0m         )\n\u001b[1;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 957\u001b[0m         _assert_all_finite(\n\u001b[1;32m    958\u001b[0m             array,\n\u001b[1;32m    959\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    960\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    961\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    964\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    123\u001b[0m     X,\n\u001b[1;32m    124\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[1;32m    125\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[1;32m    126\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[1;32m    127\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    128\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    129\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Create an Extra Trees classifier instance with hyperparameters\n",
    "extra_trees = ExtraTreesClassifier(random_state=42)     # Random seed for reproducibility\n",
    "\n",
    "# Train the Extra Trees classifier on the training data\n",
    "extra_trees.fit(preprocessing.fit_transform(X_train,y_train), y_train)\n",
    "\n",
    "# # Now you can use the trained model for predictions on new data, e.g., X_test\n",
    "# y_pred = extra_trees.predict(X_test)\n",
    "\n",
    "# # You can also assess the model's accuracy, precision, recall, etc., using appropriate evaluation metrics\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for train_index, test_index in StratifiedKFold(5).split(X_train, y_train):\n",
    "    models.models[\"lgbm_grade_single\"].pipeline.fit(\n",
    "        X_train[train_index], y_train[train_index]\n",
    "    )\n",
    "    scores.append(\n",
    "        roc_auc_score(\n",
    "            y_train[test_index],\n",
    "            models.models[\"lgbm_grade_single\"].pipeline.predict_proba(\n",
    "                X_train[test_index]\n",
    "            )[:,1],\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
