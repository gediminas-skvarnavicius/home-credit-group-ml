{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "import polars as pl\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from rgf.sklearn import RGFClassifier\n",
    "import auxiliary.transformers as tr\n",
    "from auxiliary.transformers import PolarsColumnTransformer as PCT\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import copy\n",
    "import auxiliary.tuning as tunes\n",
    "from ray import tune\n",
    "import joblib\n",
    "import numpy as np\n",
    "from BorutaShap import BorutaShap\n",
    "%aimport auxiliary.transformers\n",
    "%aimport auxiliary.tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pl.read_parquet('temp/application_train_filtered.parquet')\n",
    "id_and_target=['SK_ID_CURR','TARGET']\n",
    "X_train=train_data.drop(columns=id_and_target)\n",
    "y_train=train_data['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>AMT_INCOME_TOTAL</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>-0.003982</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌──────────────────┐\n",
       "│ AMT_INCOME_TOTAL │\n",
       "│ ---              │\n",
       "│ f64              │\n",
       "╞══════════════════╡\n",
       "│ -0.003982        │\n",
       "└──────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.DataFrame([X_train[\"AMT_INCOME_TOTAL\"],y_train]).select(pl.corr(X_train[\"AMT_INCOME_TOTAL\"].name,y_train.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (307_511,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>bureau_DAYS_CREDIT_UPDATE_mode_Active</th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>-7</td></tr><tr><td>-43</td></tr><tr><td>-83892</td></tr><tr><td>-83892</td></tr><tr><td>-83892</td></tr><tr><td>-16</td></tr><tr><td>-23</td></tr><tr><td>-18</td></tr><tr><td>-83892</td></tr><tr><td>-83892</td></tr><tr><td>-34</td></tr><tr><td>-83892</td></tr><tr><td>&hellip;</td></tr><tr><td>-21</td></tr><tr><td>-2227</td></tr><tr><td>-83892</td></tr><tr><td>-46</td></tr><tr><td>-28</td></tr><tr><td>-83892</td></tr><tr><td>-12</td></tr><tr><td>-83892</td></tr><tr><td>-83892</td></tr><tr><td>-179</td></tr><tr><td>-83892</td></tr><tr><td>-19</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (307_511,)\n",
       "Series: 'bureau_DAYS_CREDIT_UPDATE_mode_Active' [i64]\n",
       "[\n",
       "\t-7\n",
       "\t-43\n",
       "\t-83892\n",
       "\t-83892\n",
       "\t-83892\n",
       "\t-16\n",
       "\t-23\n",
       "\t-18\n",
       "\t-83892\n",
       "\t-83892\n",
       "\t-34\n",
       "\t-83892\n",
       "\t…\n",
       "\t-5\n",
       "\t-21\n",
       "\t-2227\n",
       "\t-83892\n",
       "\t-46\n",
       "\t-28\n",
       "\t-83892\n",
       "\t-12\n",
       "\t-83892\n",
       "\t-83892\n",
       "\t-179\n",
       "\t-83892\n",
       "\t-19\n",
       "]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp=tr.NumDiffFromRestImputer()\n",
    "imp.fit_transform(X_train['bureau_DAYS_CREDIT_UPDATE_mode_Active'],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_features = []\n",
    "for feature in X_train.select(pl.col(pl.Utf8)).columns:\n",
    "    if train_data[feature].n_unique() == 2:\n",
    "        bool_features.append(feature)\n",
    "\n",
    "cat_features = [\n",
    "    feature\n",
    "    for feature in X_train.select(pl.col(pl.Utf8)).columns\n",
    "    if feature not in bool_features\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([])\n",
    "cat_imputers = tr.PolarsColumnTransformer([])\n",
    "for feature in cat_features:\n",
    "    cat_imputers.steps[feature] = PCT.Step(\n",
    "        feature, tr.NotInImputerPolars(min_values=100, fill_value=\"other\"), feature\n",
    "    )\n",
    "preprocessing.steps.append((\"cat_imputers\", cat_imputers))\n",
    "\n",
    "encoders = tr.PolarsColumnTransformer([])\n",
    "for feature in bool_features:\n",
    "    encoders.steps[feature] = PCT.Step(\n",
    "        feature, tr.PolarsOneHotEncoder(drop=True), feature\n",
    "    )\n",
    "for feature in cat_features:\n",
    "    encoders.steps[feature] = PCT.Step(\n",
    "        feature, tr.TargetMeanOrderedLabeler(how=\"label\"), feature\n",
    "    )\n",
    "preprocessing.steps.append((\"encoders\", encoders))\n",
    "feature_remover = tr.FeatureRemover([])\n",
    "preprocessing.steps.append((\"feature_removal\", feature_remover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb=LGBMClassifier(n_jobs=1,verbosity=-1,force_col_wise=True)\n",
    "full_pipeline=Pipeline([('preprocess', preprocessing),('model',model_lgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_selection=LGBMClassifier(verbose=-1,random_state=1,reg_alpha=1)\n",
    "selector=BorutaShap(importance_measure='shap',model=model_for_selection)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "selector.fit(\n",
    "    full_pipeline[\"preprocess\"]\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .to_pandas(),\n",
    "    y_train.to_pandas(),\n",
    ")\n",
    "joblib.dump(selector,'temp/model_1_selector.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector=joblib.load('temp/model_1_selector.joblib')\n",
    "bad_features=selector.features_to_remove.tolist()\n",
    "bad_and_tentative_features=bad_features.copy()\n",
    "bad_and_tentative_features.extend(selector.tentative.copy())\n",
    "feature_removal_list=[bad_features,bad_and_tentative_features,[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tunes.Models()\n",
    "search_space_lgbm = {\n",
    "    \"preprocess__feature_removal__feats_to_drop\": tune.choice(feature_removal_list),\n",
    "    \"model__max_depth\": tune.randint(5, 50),\n",
    "    \"model__num_leaves\": tune.randint(10, 3051),\n",
    "    \"model__n_estimators\": tune.randint(10, 251),\n",
    "    \"model__learning_rate\": tune.loguniform(0.001, 0.1),\n",
    "    \"model__bagging_freq\": tune.randint(0, 11),\n",
    "    \"model__colsample_bytree\": tune.uniform(0.2, 1.0),\n",
    "    \"model__subsample\": tune.uniform(0.2, 1.0),\n",
    "    \"model__reg_alpha\": tune.loguniform(0.001, 100),\n",
    "    \"model__reg_lambda\": tune.loguniform(0.001, 100),\n",
    "    \"model__boosting_type\": tune.choice([\"gbdt\", \"dart\", \"rf\"]),\n",
    "    \"model__class_weight\": tune.choice([\"balanced\", None]),\n",
    "    \"model__max_bin\": tune.randint(5, 201),\n",
    "}\n",
    "\n",
    "models.add_model(\n",
    "    \"lgbm\", full_pipeline, search_space_lgbm, metric_threshold=0.75\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_with_nulls = (\n",
    "    pl.Series(\n",
    "        X_train.select(pl.col(pl.FLOAT_DTYPES), pl.col(pl.INTEGER_DTYPES)).columns\n",
    "    )\n",
    "    .filter(\n",
    "        X_train.select(pl.col(pl.FLOAT_DTYPES), pl.col(pl.INTEGER_DTYPES))\n",
    "        .select(pl.all().is_null().any())\n",
    "        .transpose()\n",
    "        .to_series()\n",
    "    )\n",
    "    .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_etrees=copy.deepcopy(preprocessing)\n",
    "num_imputer = tr.PolarsColumnTransformer([])\n",
    "for feature in numeric_features_with_nulls:\n",
    "    num_imputer.steps[feature] = PCT.Step(\n",
    "        feature, tr.NumDiffFromRestImputer(), feature\n",
    "    )\n",
    "preprocessing_etrees.steps.insert(0,('num_imputer', num_imputer))\n",
    "# Create an Extra Trees classifier instance with hyperparameters\n",
    "model_extra_trees = ExtraTreesClassifier(random_state=1)     # Random seed for reproducibility\n",
    "full_pipeline_etrees=Pipeline([('preprocess',preprocessing_etrees),('model',model_extra_trees)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_rgf = copy.deepcopy(preprocessing_etrees)\n",
    "model_rgf = RGFClassifier()\n",
    "full_pipeline_rgf = Pipeline([(\"preprocess\", preprocessing_rgf), (\"model\", model_rgf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-11-01 13:10:00</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:04.42        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.5/31.2 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 2.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  model__bagging_freq</th><th>model__boosting_type  </th><th>model__class_weight  </th><th style=\"text-align: right;\">         model__colsample_byt\n",
       "ree</th><th style=\"text-align: right;\">  model__learning_rate</th><th style=\"text-align: right;\">  model__max_bin</th><th style=\"text-align: right;\">  model__max_depth</th><th style=\"text-align: right;\">  model__n_estimators</th><th style=\"text-align: right;\">  model__num_leaves</th><th style=\"text-align: right;\">  model__reg_alpha</th><th style=\"text-align: right;\">  model__reg_lambda</th><th style=\"text-align: right;\">  model__subsample</th><th>...ocess__feature_re\n",
       "moval__feats_to_drop                     </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TrainableCV_8ba9c83e</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">                    7</td><td>dart                  </td><td>                     </td><td style=\"text-align: right;\">0.276289</td><td style=\"text-align: right;\">             0.0423578</td><td style=\"text-align: right;\">             136</td><td style=\"text-align: right;\">                42</td><td style=\"text-align: right;\">                   55</td><td style=\"text-align: right;\">                912</td><td style=\"text-align: right;\">          0.394023</td><td style=\"text-align: right;\">           0.323181</td><td style=\"text-align: right;\">           0.33664</td><td>[&#x27;CNT_CHILDREN&#x27;_1180</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 13:10:00,155\tWARNING tune.py:194 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-11-01 13:10:00,244\tWARNING experiment_state.py:371 -- Experiment checkpoint syncing has been triggered multiple times in the last 30.0 seconds. A sync will be triggered whenever a trial has checkpointed more than `num_to_keep` times since last sync or if 300 seconds have passed since last sync. If you have set `num_to_keep` in your `CheckpointConfig`, consider increasing the checkpoint frequency or keeping more checkpoints. You can supress this warning by changing the `TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S` environment variable.\n",
      "2023-11-01 13:10:01,097\tINFO tune.py:1143 -- Total run time: 5.28 seconds (4.33 seconds for the tuning loop).\n",
      "2023-11-01 13:10:01,097\tWARNING tune.py:1158 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/tmp/tune_results/lgbm\", trainable=...)\n",
      "2023-11-01 13:10:01,100\tWARNING experiment_analysis.py:205 -- Failed to fetch metrics for 1 trial(s):\n",
      "- TrainableCV_8ba9c83e: FileNotFoundError('Could not fetch metrics for TrainableCV_8ba9c83e: both result.json and progress.csv were not found at /tmp/tune_results/lgbm/TrainableCV_8ba9c83e_1_model__bagging_freq=7,model__boosting_type=dart,model__class_weight=None,model__colsample_bytree=0.2763,mod_2023-11-01_13-09-55')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sklearn.pipeline.Pipeline.set_params() argument after ** must be a mapping, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gediminas/Documents/turing_projects/module3_s4/gskvar-ML.4/model_1_difficulties.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m models\u001b[39m.\u001b[39;49mtune_all(X_train,y_train,metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mroc_auc\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/turing_projects/module3_s4/gskvar-ML.4/auxiliary/tuning.py:383\u001b[0m, in \u001b[0;36mModels.tune_all\u001b[0;34m(self, X_train, y_train, X_val, y_val, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39moverride_n:\n\u001b[1;32m    382\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39moverride_n\n\u001b[0;32m--> 383\u001b[0m model\u001b[39m.\u001b[39;49mtune_model(X_train, y_train, X_val, y_val, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    384\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m tuned.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/turing_projects/module3_s4/gskvar-ML.4/auxiliary/tuning.py:312\u001b[0m, in \u001b[0;36mModels.Model.tune_model\u001b[0;34m(self, X_train, y_train, X_val, y_val, n, n_iter, sample_size, metric, stratify)\u001b[0m\n\u001b[1;32m    310\u001b[0m results \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mfit()\n\u001b[1;32m    311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_params \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mget_best_result()\u001b[39m.\u001b[39mconfig\n\u001b[0;32m--> 312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_params)\n",
      "\u001b[0;31mTypeError\u001b[0m: sklearn.pipeline.Pipeline.set_params() argument after ** must be a mapping, not NoneType"
     ]
    }
   ],
   "source": [
    "models.tune_all(X_train,y_train,metric='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.models['lgbm_grade_single'].best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for train_index, test_index in StratifiedKFold(5).split(X_train, y_train):\n",
    "    full_pipeline_etrees.fit(\n",
    "        X_train[train_index], y_train[train_index]\n",
    "    )\n",
    "    try:\n",
    "        scores.append(\n",
    "            roc_auc_score(\n",
    "                y_train[test_index],\n",
    "                full_pipeline_etrees.predict_proba(\n",
    "                    X_train[test_index]\n",
    "                )[:,1],\n",
    "            )\n",
    "        )\n",
    "    except:\n",
    "        bad_df=full_pipeline_etrees['preprocess'].transform(X_train[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for train_index, test_index in StratifiedKFold(5).split(X_train, y_train):\n",
    "    models.models[\"lgbm_grade_single\"].pipeline.fit(\n",
    "        X_train[train_index], y_train[train_index]\n",
    "    )\n",
    "    scores.append(\n",
    "        roc_auc_score(\n",
    "            y_train[test_index],\n",
    "            models.models[\"lgbm_grade_single\"].pipeline.predict_proba(\n",
    "                X_train[test_index]\n",
    "            )[:,1],\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
